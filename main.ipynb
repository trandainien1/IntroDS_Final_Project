{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction To Data Science - Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Group members:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Name              | ID       |\n",
        "|-------------------|----------|\n",
        "| Pham Dang Son Ha |21127206|\n",
        "| Tran Dai Nien     | 21127664 |\n",
        "| Nguyen Cao Khoi   | 21127632 |\n",
        "| Nguyen Phan Minh Triet  | 21126007  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. [Data Collection](#data-collection)\n",
        "\n",
        "2. [Data Preprocessing and Exploration](#data-preprocessing-and-exploration)\n",
        "\n",
        "3. [Data Modeling](#data-modeling)\n",
        "\n",
        "4. [Reference](#references)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Set-up environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Import Required Libraries: Import the necessary Python libraries - requests, BeautifulSoup, pandas, and time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bs4 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (from bs4) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
            "Requirement already satisfied: requests in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (from requests) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (from requests) (1.26.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: pandas in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (2.1.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (from pandas) (1.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\phamdangsonha\\anaconda3\\envs\\min_ds-env\\lib\\site-packages (1.26.0)\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'xgboost'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Regression Models\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVR\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ElasticNet\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SGDRegressor\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
          ]
        }
      ],
      "source": [
        "# ignore warning\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Necessary Packages\n",
        "!pip install bs4\n",
        "!pip install requests\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install xgboost\n",
        "\n",
        "import time\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split # Split dataset into train set and test set\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RandomizedSearchCV # Hyperparamater tuning\n",
        "from sklearn.model_selection import cross_val_score # Evaluate model\n",
        "\n",
        "# Regression Models\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import mean_squared_error \n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# TF-IDF:  find relative frequency of a word in a document(used for suggesting relate films)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# calculate the similarity between two vectors in the feature space\n",
        "from sklearn.metrics.pairwise import linear_kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Collect data from a website by parsing HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### List of collected information\n",
        "\n",
        "Information related to the movie, including:\n",
        "\n",
        "- `names`: Movie titles.\n",
        "- `years`: Release years of the movies.\n",
        "- `genres`: Categories or genres the movies belong to.\n",
        "- `lengths`: Duration or length of the movies.\n",
        "- `rating_stars`: Ratings received by the movies.\n",
        "- `metascores`: Metascores assigned to the movies (if available).\n",
        "- `votes`: Total votes accumulated by the movies.\n",
        "- `grosses`: Box office gross earnings of the movies (if available).\n",
        "- `directors`: Directors of the movies.\n",
        "- `stars`: Lead actors/actresses in the movies.\n",
        "- `descriptions`: Synopsis or descriptions of the movies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Collection Process:\n",
        "\n",
        "- Identify the URL of the webpage containing the list of movies to be scraped.\n",
        "- Use the requests library to send GET requests to each page of the IMDb website.\n",
        "- Parse the HTML of the webpage using BeautifulSoup to extract information about the movies.\n",
        "- Iterate through each movie to collect details such as title, release year, genre, rating, - Metascore, votes, earnings, director, main cast, and description.\n",
        "- Store the collected information in a DataFrame using the pandas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect_data(base_url, num_movies, movies_per_page=100):\n",
        "    # Initialize lists for storing data\n",
        "    names = []\n",
        "    years = []\n",
        "    genres = []\n",
        "    lengths = []\n",
        "    rating_stars = []\n",
        "    metascores = []\n",
        "    votes = []\n",
        "    grosses = []\n",
        "    directors = []\n",
        "    stars = []\n",
        "    descriptions = []\n",
        "\n",
        "    # Iterate over the specified number of pages\n",
        "    for page in range(1, int(num_movies / movies_per_page) + 1):\n",
        "        try:\n",
        "            # Construct the URL for the current page\n",
        "            url = f\"{base_url}&page={page}\"\n",
        "            \n",
        "            # Send a GET request to the URL\n",
        "            response = requests.get(url)\n",
        "            time.sleep(2)  # Respectful crawling by adding delay\n",
        "\n",
        "            # Check if the response status code is 200 (OK)\n",
        "            if response.status_code == 200:\n",
        "                # Parse the HTML content of the page\n",
        "                soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "                # Find all movie containers on the page\n",
        "                movies = soup.find_all('div', class_='lister-item-content')\n",
        "\n",
        "                # Process each movie\n",
        "                for movie in movies:\n",
        "                    # Extract movie details\n",
        "                    name = movie.find('h3').find('a').text.strip()\n",
        "                    year = movie.find('span', class_='lister-item-year').text.strip('()')\n",
        "                    genre = movie.find('span', class_='genre').text.strip()\n",
        "                    length = movie.find('span', class_='runtime').text.strip().split()[0]\n",
        "                    rating = movie.find('span', class_='ipl-rating-star__rating').text.strip()\n",
        "\n",
        "                    # Some movies might not have a metascore\n",
        "                    metascore_tag = movie.find('span', class_='metascore')\n",
        "                    metascore = metascore_tag.text.strip() if metascore_tag else 'N/A'\n",
        "\n",
        "                    # Extract votes and gross, if available\n",
        "                    nv_tags = movie.find_all('span', attrs={'name': 'nv'})\n",
        "                    vote = nv_tags[0].text if nv_tags else 'N/A'\n",
        "                    gross = nv_tags[1].text if len(nv_tags) > 1 else 'N/A'\n",
        "\n",
        "                    # Extract director and stars\n",
        "                    director, *star_list = movie.find_all('a', href=lambda href: href and 'name/nm' in href)\n",
        "                    director = director.text\n",
        "                    stars_str = ', '.join(star.text for star in star_list)\n",
        "\n",
        "                    # Extract description\n",
        "                    description = movie.find_all('p', class_='')[-1].text.strip()\n",
        "\n",
        "                    # Append the extracted data to respective lists\n",
        "                    names.append(name)\n",
        "                    years.append(year)\n",
        "                    genres.append(genre)\n",
        "                    lengths.append(length)\n",
        "                    rating_stars.append(rating)\n",
        "                    metascores.append(metascore)\n",
        "                    votes.append(vote)\n",
        "                    grosses.append(gross)\n",
        "                    directors.append(director)\n",
        "                    stars.append(stars_str)\n",
        "                    descriptions.append(description)\n",
        "\n",
        "            else:\n",
        "                print(f\"Failed to process page {page}: Status code {response.status_code}\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request error on page {page}: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error on page {page}: {e}\")\n",
        "\n",
        "    # Create a DataFrame with the collected data\n",
        "    data = pd.DataFrame({\n",
        "        'Name': names,\n",
        "        'Year': years,\n",
        "        'Genre': genres,\n",
        "        'Length': lengths,\n",
        "        'Rating': rating_stars,\n",
        "        'Metascore': metascores,\n",
        "        'Votes': votes,\n",
        "        'Gross': grosses,\n",
        "        'Director': directors,\n",
        "        'Stars': stars,\n",
        "        'Description': descriptions\n",
        "    })\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Collecting Movie Data from IMDb\n",
        "\n",
        "- Identify the URL of the webpage containing the list of movies to be scraped.\n",
        "\n",
        "- Use the collect_data function to gather information from the webpage based on the desired number of pages and movies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the URL containing the list of movies\n",
        "url = \"https://www.imdb.com/list/ls051785783/?st_dt=&mode=detail&sort=list_order,asc\"\n",
        "\n",
        "# Scrape the data\n",
        "\n",
        "if os.path.isfile('data_film.csv'):\n",
        "  data_film = pd.read_csv('data_film.csv')\n",
        "else: \n",
        "  data_film = collect_data(url, 1500, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Store the collected data in a CSV file named data_film.csv using data_film.to_csv().\n",
        "- Read the data from the CSV file into a new DataFrame (data_film) using pd.read_csv()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Save to csv file with name data_film.csv\n",
        "# Save the DataFrame to a CSV file without including the index\n",
        "data_film.to_csv(\"data_film.csv\", index=False)\n",
        "\n",
        "# Read the CSV file into a new DataFrame called data_film\n",
        "data_film = pd.read_csv(\"data_film.csv\")\n",
        "\n",
        "# Display the 'data_film' DataFrame\n",
        "data_film"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing And Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1) How many rows and columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- There are 1500 rows and 11 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) What is the meaning of each row?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Each row represents the information of a film(name, year, genres,...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Are there duplicated rows?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is 0 duplicated row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4) What is the meaning of each columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `names`: Movie titles.\n",
        "- `years`: Release years of the movies.\n",
        "- `genres`: Categories or genres the movies belong to.\n",
        "- `lengths`: Duration or length of the movies.\n",
        "- `rating_stars`: Ratings received by the movies.\n",
        "- `metascores`: Metascores assigned to the movies (if available).\n",
        "- `votes`: Total votes accumulated by the movies.\n",
        "- `grosses`: Box office gross earnings of the movies (if available).\n",
        "- `directors`: Directors of the movies.\n",
        "- `stars`: Lead actors/actresses in the movies.\n",
        "- `descriptions`: Synopsis or descriptions of the movies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5) What is the current data type of each column? Are there any columns having inappropriate data types?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.sample(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- There are some columns which have inappropriate type: `Year, Votes, Gross`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- For `Year, Votes` we can simply convert them into **numeric**. But with `Gross` we need to change columns name to `Gross(M$)` to indicated that `Gross` unit is million Dollars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove ',' in Votes\n",
        "data_film.Votes = data_film.Votes.str.replace(',', '')\n",
        "\n",
        "# remove $, M in Gross and create new column `Gross(M$)`\n",
        "data_film['Gross(M$)'] = data_film.Gross.str.replace('M', '').str.replace('$', '')\n",
        "\n",
        "# drop Gross\n",
        "data_film.drop(columns='Gross', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.sample(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Convert them into **numeric**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "to_numeric_cols = ['Year', 'Votes', 'Gross(M$)']\n",
        "\n",
        "for col in to_numeric_cols:\n",
        "  data_film[col] = pd.to_numeric(data_film[col], errors='coerce')\n",
        "\n",
        "data_film.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6) With each numerical column, how are values distributed?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- All numerical columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical_cols = data_film.columns[(data_film.dtypes != 'object')]\n",
        "numerical_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6.1) What is the percentage of missing values?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Number of missing values of each columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film[numerical_cols].info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The percentage of missing values for each columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_data_film_missing_percentage = (data_film.isnull().mean() * 100).sort_values()\n",
        "plt.barh(sorted_data_film_missing_percentage.index, sorted_data_film_missing_percentage.values)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> `Gross(M$)` and `Metascore` missing value's percentage are high"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- the `Year` missing values is not significant, so we can drop observations which has missing `Year` value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.dropna(subset=['Year'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- For `Gross(M$)` and `Metascore`, we will impute median for missing value "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = ['Gross(M$)', 'Metascore']\n",
        "\n",
        "for col in cols:\n",
        "    data_film[col].fillna(data_film[col].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Check if any missing values left"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The distribution of numerical attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film[numerical_cols].hist(figsize=(15, 10))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- General statistics of numerical attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film[numerical_cols].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7) With each categorical column, how are values distributed?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Quick glance at categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_cols = data_film.columns[data_film.dtypes == 'object']\n",
        "\n",
        "categorical_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Convert object to category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_data_film = data_film.copy()\n",
        "for label, content in data_film.items():\n",
        "    if pd.api.types.is_string_dtype(content):\n",
        "        new_data_film[label] = pd.Categorical(content).codes + 1 # -1 means there is missing value. so we +1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_data_film.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Missing values = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in categorical_cols:\n",
        "    print(new_data_film[col].isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The distribution of `Name`: the counts is not significantly different so we won't plot this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.Name.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The distribution of `Genre`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.Genre.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The distribution of top 20 `Genres`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "genre_counts = data_film.Genre.value_counts()[:20]\n",
        "plt.barh(genre_counts.index, genre_counts.values)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The distribution of `Director`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.Director.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The distribution of top 20 `Director`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "director_counts = data_film.Director.value_counts()[:20]\n",
        "plt.barh(director_counts.index, director_counts.values);\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The distribution of `Stars`: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Top 10 lead stars and their participated movies' count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "star_counts = data_film.Stars.value_counts()[:10].sort_values()\n",
        "plt.barh(star_counts.index, star_counts.values);\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The distribution of `Description`: each description is different so we won't plot this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film.Description.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7.1) What is the percentage of missing values?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- As we can see all the categorical columns has 0 missing value so the perccentage will be: 0%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8) Are they abnormal?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- After considering the distribution of each attributes, we can conclude that the values are good enough for us to use for model training and get insights from them. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9) Making questions for exploration?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9.1) Question 1: Which genres should we as a director want to make with?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Purposes: By analyzing historical data on movie ratings and box office performance across different genres, we can identify which genres tend to be more well-received by audiences and/or more profitable. This can help the director choose a genre that aligns with their goals, whether it’s to create a critically acclaimed film, a box office hit, or both."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Approaches: \n",
        "\n",
        "    + `Analyzing on Rating`: We can group the data by genres and calculate the average Rating (or Metascore) for each genre. This can give us an idea of which genres are generally more well-received.\n",
        "\n",
        "    + `Analyzing on Gross`: We can group the data by genres and calculate the average Gross for each genre. This can give us an idea of which genres are generally more profitable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Exploring about the genre of the movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We'll split the genres column into separate rows\n",
        "df_genres = data_film.assign(Genre_Split=data_film['Genre'].str.split(',')).explode('Genre_Split')\n",
        "\n",
        "# Remove leading and trailing spaces\n",
        "df_genres['Genre_Split'] = df_genres['Genre_Split'].str.strip()\n",
        "\n",
        "# Get unique genres\n",
        "unique_genres = df_genres['Genre_Split'].unique()\n",
        "\n",
        "# Print the number of unique genres\n",
        "print(\"Number of unique genres:\", len(unique_genres))\n",
        "\n",
        "# Print all unique genres\n",
        "print(\"Unique genres:\", unique_genres)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Explanation:\n",
        "\n",
        "    + `Crime`: These films revolve around the sinister actions of criminals, mobsters, bank robbers, underworld figures, and ruthless hoodlums who operate outside the law, stealing and murdering their way through life.\n",
        "    \n",
        "    + `Drama`: Drama films are serious presentations or stories with settings or life situations that portray realistic characters in conflict with either themselves, others, or forces of nature.\n",
        "\n",
        "    + `Romance`: Romance films are love stories that focus on passion, emotion, and the affectionate romantic involvement of the main characters, and the journey that their love takes them through dating, courtship or marriage.\n",
        "    \n",
        "    + `War`: War films acknowledge the horror and heartbreak of war, letting the actual combat fighting or conflict (against nations or humankind) provide the primary plot or background for the action of the film.\n",
        "\n",
        "    + `Comedy`: Comedies are light-hearted plots consistently and deliberately designed to amuse and provoke laughter (with one-liners, jokes, etc.) by exaggerating the situation, the language, action, relationships and characters.\n",
        "\n",
        "    + `Mystery`: These are types of films that make us think and keep us guessing. They deal with our sense of unease and anxiety.\n",
        "\n",
        "    + `Action`: Action films usually include high energy, big-budget physical stunts and chases, possibly with rescues, battles, fights, escapes, destructive crises (floods, explosions, natural disasters, fires, etc.), non-stop motion, spectacular rhythm and pacing, and adventurous, often two-dimensional ‘good-guy’ heroes (or recently, heroines) battling ‘bad guys’ - all designed for pure audience escapism.\n",
        "    \n",
        "    + `Western`: Westerns are the major defining genre of the American film industry, a nostalgic eulogy to the early days of the expansive, untamed American frontier (the borderline between civilization and the wilderness).\n",
        "    \n",
        "    + `Thriller`: Thrillers are tension-laden, complex, mysterious, and often involve crime (solution of a murder, disappearance, theft, etc.).\n",
        "    \n",
        "    + `Adventure`: Adventure films are exciting stories, with new experiences or exotic locales, very \n",
        "    similar to or often paired with the action film genre.\n",
        "\n",
        "    + `Family`: These are films that are designed to be suitable for all ages.\n",
        "\n",
        "    + `Fantasy`: Fantasy films are films with fantastic themes, usually involving magic, supernatural \n",
        "    events, mythology, folklore, or exotic fantasy worlds.\n",
        "    \n",
        "    + `Film-Noir`: Film noir is a cinematic term used primarily to describe stylish Hollywood crime dramas, particularly those that emphasize cynical attitudes and sexual motivations.\n",
        "    \n",
        "    + `Biography`: These films depict and dramatize the life of an important historical personage (or group) from the past or present era.\n",
        "    \n",
        "    + `History`: Films in this genre focus on recreating a specific and important period or event in history.\n",
        "    \n",
        "    + `Sci-Fi`: Science fiction films are often quasi-scientific, visionary and imaginative - complete with heroes, aliens, distant planets, impossible quests, improbable settings, fantastic places, great dark and shadowy villains, futuristic technology, unknown and unknowable forces, and extraordinary monsters (‘things or creatures from space’), either created by mad scientists or by nuclear havoc.\n",
        "    \n",
        "    + `Sport`: Sports films are those that have a sports setting (football or baseball stadium, arena, or the Olympics, etc.), competitive event (the ‘big game,’ ‘fight,’ or ‘race’), athletes (boxers, racers, etc.), or coach in the storyline.\n",
        "    \n",
        "    + `Horror`: Horror films are designed to frighten and to invoke our hidden worst fears, often in a terrifying, shocking finale, while captivating and entertaining us at the same time in a cathartic experience.\n",
        "    \n",
        "    + `Music`: These are films that are centered around music and dance.\n",
        "    \n",
        "    + `Musical`: Musicals/Dance films are cinematic forms that emphasize and showcase full-scale song and dance routines in a significant way (usually with a musical or dance performance integrated as part of the film narrative, or as an unrealistic “eruption” within the film).\n",
        "\n",
        "    + `Animation`: Animated films are ones in which individual drawings, paintings, or illustrations are photographed frame by frame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Analyzing on Rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Then, we group by genres and calculate the average rating_stars\n",
        "average_ratings = df_genres.groupby('Genre_Split')['Rating'].mean()\n",
        "\n",
        "# Finally, we sort the result in descending order so the genres with the highest average ratings are on top\n",
        "average_ratings = average_ratings.sort_values(ascending=False)\n",
        "\n",
        "# Get the top 5 and bottom 5 genres\n",
        "top_5 = average_ratings.head(5)\n",
        "bottom_5 = average_ratings.tail(5)\n",
        "\n",
        "# Combine them into one Series\n",
        "combined = pd.concat([top_5, bottom_5])\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=combined.index, y=combined.values)\n",
        "plt.title('Average Ratings of Top 5 Best and Worst Genres')\n",
        "plt.xlabel('Genre')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "=> Conclusion: Based on the data analysis, the top five genres with the highest average rating scores are Horror, Animation, Film-Noir, War, and Mystery. This suggests that movies in these genres tend to be more well-received by audiences, as indicated by their higher average ratings.\n",
        "\n",
        "On the other hand, the genres with the lowest average rating scores are Musical, Comedy, Sport, Romance, Music. This suggests that movies in these genres tend to receive lower ratings from audiences.\n",
        "\n",
        "This analysis provides a general trend and can be a useful guide for filmmakers when choosing a genre for their next project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Analyzing on Gross"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by genres and calculate the average gross\n",
        "average_gross = df_genres.groupby('Genre_Split')['Gross(M$)'].mean()\n",
        "\n",
        "# Sort the result in descending order so the genres with the highest average gross are on top\n",
        "average_gross = average_gross.sort_values(ascending=False)\n",
        "\n",
        "# Get the top 5 and bottom 5 genres\n",
        "top_5_gross = average_gross.head(5)\n",
        "bottom_5_gross = average_gross.tail(5)\n",
        "\n",
        "# Combine them into one Series\n",
        "combined_gross = pd.concat([top_5_gross, bottom_5_gross])\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=combined_gross.index, y=combined_gross.values)\n",
        "plt.title('Average Gross of Top 5 Best and Worst Genres')\n",
        "plt.xlabel('Genre')\n",
        "plt.ylabel('Average Gross')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "=> Conclusion: Based on the data analysis, the top five genres with the highest average gross are Fantasy, Animation, Adventure, Action and Sci-Fi. This suggests that movies in these genres tend to be more profitable, as indicated by their higher gross.\n",
        "\n",
        "On the other hand, the genres with the lowest gross are Film-Noir, Horror, Musical, Western and Music. This suggests that movies in these genres tend to receive lower gross and not popluar with audiences.\n",
        "\n",
        "This analysis provides a general trend and can be a useful guide for filmmakers when choosing a genre for their next project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Final conclusion: \n",
        "\n",
        "    + Animation is the genre which tend to be more favoured by audiences and bring more profit for the filmakers because of it's high value on both Rating and Gross\n",
        "    \n",
        "    + Music and Musical are the 2 types of genre that generally bring low income to the company and are not favourable among audiences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9.2) Question 2: How have the movie lengths and genres evolved over the year?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Purpose: \n",
        "\n",
        "    + To understand the trends and changes in movie lengths and genres over time. This can provide insights into how the film industry has evolved and changed, reflecting shifts in cultural tastes, technological advancements, and other factors.\n",
        "\n",
        "    + By analyzing this, we can gain a deeper understanding of the film industry’s history and potentially predict future trends. For filmmakers, this information could be useful in making decisions about what type of films to produce. For film enthusiasts or researchers, it could provide interesting insights into the evolution of cinema. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Appoaches:\n",
        "\n",
        "    + `Yearly Average Movie Length`: Group the data by year and calculate the average movie length for each year. Plotting these averages over time can show how movie lengths have changed.\n",
        "\n",
        "    + `Genre Popularity Over Time`: For each year, calculate the number of movies produced in each genre. Plotting these numbers can show how the popularity of different genres has evolved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Yearly Average Movie Length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by year and calculate the average length\n",
        "average_lengths = data_film.groupby('Year')['Length'].mean()\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "average_lengths.plot(kind='line')\n",
        "plt.title('Average Movie Length Over Time')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average Length')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "=> Conclusion: Over the given period, the length of movies as a whole decrease from roughly 200 minutes to around 90 minutes per movie.\n",
        "Around 1920, the length of the movies witnessed a sharp decrease from around 200 to 75 minutes. After that time the length of the movies fuctuate between 60 and 120 minutes. In the recent years the length of the movies is falling and likely still fall in the future\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Genre Popularity Over Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Make a copy of df_genres\n",
        "copy_df_genres = df_genres.copy()\n",
        "\n",
        "# Get the top 5 genres\n",
        "top_genres = copy_df_genres['Genre_Split'].value_counts().index[:6]\n",
        "\n",
        "# Replace all other genres with 'Other'\n",
        "copy_df_genres['Genre_Split'] = copy_df_genres['Genre_Split'].where(copy_df_genres['Genre_Split'].isin(top_genres), 'Other')\n",
        "\n",
        "# Convert the 'Year' column to numeric, coercing errors to NaN\n",
        "copy_df_genres['Year'] = pd.to_numeric(copy_df_genres['Year'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaN in the 'Year' column\n",
        "copy_df_genres = copy_df_genres.dropna(subset=['Year'])\n",
        "\n",
        "# Divide the data into six time periods\n",
        "copy_df_genres['Time_Period'] = pd.cut(copy_df_genres['Year'], bins=6)\n",
        "\n",
        "# Count the number of movies in each genre for each time period\n",
        "genre_counts = copy_df_genres.groupby(['Time_Period', 'Genre_Split']).size()\n",
        "\n",
        "# Reset the index to make 'Time_Period' and 'Genre_Split' regular columns\n",
        "genre_counts = genre_counts.reset_index(name='Count')\n",
        "\n",
        "# Get the unique time periods\n",
        "time_periods = genre_counts['Time_Period'].unique()\n",
        "\n",
        "# Create a 2x3 grid of subplots\n",
        "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "# Loop over the time periods and plot the data in a separate subplot\n",
        "for i, period in enumerate(time_periods):\n",
        "    # Get the data for this time period\n",
        "    data = genre_counts[genre_counts['Time_Period'] == period]\n",
        "    \n",
        "    # Calculate the row and column indices for the subplot\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "    \n",
        "    # Create the pie chart in the subplot\n",
        "    axs[row, col].pie(data['Count'], labels=data['Genre_Split'], autopct='%1.1f%%')\n",
        "    axs[row, col].set_title('Genre Popularity in ' + str(int(period.left)) + '-' + str(int(period.right)))\n",
        "\n",
        "# Add a legend\n",
        "fig.legend(genre_counts['Genre_Split'].unique(), loc='upper left')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "=> Conclusion: In general, Drama , which over the six period accounts for 20%-25%, is the most popular genre among all.\n",
        "\n",
        "Over the time, the proportion of Crime, Adventure and Action increase over the years. In contrast, the percentage of Comedy and Romance movies falls over the given period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Final conclusion:\n",
        "\n",
        "+ The length of a movie decrease over time and this status seem to continue in the future\n",
        "\n",
        "+ Drama movie is the most popular movie type. Over the time the proportion of Crime, Adventure and Action increases, the percentage of Comedy and Romance decreases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9.3) Question 3: Does a good movie  comes with certain actors/actress?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Purposes:\n",
        "\n",
        "    + To understand if the presence of certain actors or actresses in a movie can be a predictor of the movie’s quality or success. It can help in understanding trends in the film industry and can potentially guide decisions about casting for future films.\n",
        "\n",
        "    + Help viewers to find the good movies to watch just based on the casts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Approaches:\n",
        "\n",
        "    + Step 1 - Define Success: We need to define what a “good” movie is. It could be based on Rating, Gross, or a combination of factors.\n",
        "\n",
        "    + Step 2 - Analyze Movie Success: For each actors/actresses, calculate the average Rating and Gross of the movies they’ve starred in. Compare these averages to the overall averages to see if movies featuring these actors/actresses tend to be more successful.\n",
        "\n",
        "    + Step 3 - Visualize the Results: Create bar plots or other visualizations to compare the success of movies with different actors/actresses. This could help visually identify any trends or patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Exploring about the Stars in the movie data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We'll split the Stars column into separate rows\n",
        "df_stars = data_film.assign(Stars_Split=data_film['Stars'].str.split(',')).explode('Stars_Split')\n",
        "\n",
        "# Remove leading and trailing spaces\n",
        "df_stars['Stars_Split'] = df_stars['Stars_Split'].str.strip()\n",
        "\n",
        "# Get unique stars\n",
        "unique_stars = df_stars['Stars_Split'].unique()\n",
        "\n",
        "# Print the number of unique stars\n",
        "print(\"Number of unique stars:\", len(unique_stars))\n",
        "\n",
        "# Print all unique stars\n",
        "print(\"Unique stars:\", unique_stars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Exploring the success of each star"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the median of 'Gross(M$)'\n",
        "gross_median = df_stars['Gross(M$)'].median()\n",
        "\n",
        "# Fill in missing values in 'Gross(M$)' with the median\n",
        "df_stars['Gross(M$)'].fillna(gross_median, inplace=True)\n",
        "\n",
        "# Normalize 'grosses' to a 0-10 scale to create 'Gross_Point'\n",
        "df_stars['Gross_Point'] = (df_stars['Gross(M$)'] - df_stars['Gross(M$)'].min()) / (df_stars['Gross(M$)'].max() - df_stars['Gross(M$)'].min()) * 10\n",
        "\n",
        "# Create 'Success' column as the average of 'rating_stars' and 'Gross_Point'\n",
        "df_stars['Success'] = df_stars[['Rating', 'Gross_Point']].mean(axis=1)\n",
        "\n",
        "# Group the data by 'Stars_Split' and calculate the average 'Success' for each star\n",
        "average_success= df_stars.groupby('Stars_Split')['Success'].mean()\n",
        "\n",
        "# Sort the average success scores in descending order\n",
        "average_success = average_success.sort_values(ascending=False)\n",
        "\n",
        "# Get the top 5 stars with the highest and lowest average success scores\n",
        "top_5 = average_success.head(5)\n",
        "bottom_5 = average_success.tail(5)\n",
        "\n",
        "# Combine the top 5 and bottom 5 stars into one Series\n",
        "combined = pd.concat([top_5, bottom_5])\n",
        "\n",
        "# Create a bar plot of the average success scores of the top 5 and bottom 5 stars\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=combined.index, y=combined.values)\n",
        "plt.title('Average Success Score of Top 5 Best and Worst Stars')\n",
        "plt.xlabel('Star')\n",
        "plt.ylabel('Average Success Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Final conclusion:\n",
        "\n",
        "+ We can see that the top 5 best actors includes: Zoe Saldana, Billy Zane, Rob Minkoff, Henry Thomas and Dee Wallace. These are the people who tend to make the movies, in which they play a role, successful. Filmmaker should prioritize these casts.\n",
        "\n",
        "+ On the contrary, Ken Hughes, Robert Parrish, Richard Talmadge, Joseph McGrath and Anne Twomey are the 5 stars who seem not to contribute to the success of the movies because of their low Success Score. Filmmaker should avoid these casts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9.4) Question 4: Are there any correlations between Rating and Length, Votes, Gross(M$)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Purpose: To understand if there are any relationships between the rating of a movie and its length, the number of votes it received, and its gross earnings. This can provide insights into what factors might influence a movie’s rating. These insights could be useful for filmmakers, critics, and audiences alike. For example, if a factor is positive correlation with the rating of movies, the filmmakers will focus on that factor to enhance the movie quality. On the other hand, if a factor is negative correlation with the rating of movies, the filmmakers will avoid that factor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Approaches: Using heat map to display the correlation between each attributes: Rating, Length, Votes, Gross(M$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a smaller DataFrame with only the columns we're interested in\n",
        "df_small = data_film[['Rating', 'Length', 'Votes', 'Gross(M$)']]\n",
        "\n",
        "# Then, we calculate the correlation matrix\n",
        "corr_matrix = df_small.corr()\n",
        "\n",
        "# Finally, we create a heatmap of the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, square=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Final conclusion:\n",
        "\n",
        "- There is a moderate correlation between Rating and the Votes attribute. This indicates that the movies which receive a high number of Votes tend to have high Rating\n",
        "\n",
        "- The Length and Gross of the movies don't affect most to the Rating of that movies. It means that the movies with a large budget doesn't mean it is a good movie and vice versa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9.5) Question 5: Which director - actor pair often works together?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Purposes: To identify frequent collaborations between directors and actors in the film industry. This can provide insights into professional relationships and recurring partnerships in filmmaking. Certain director-actor pairs often work together because they share a common vision, have a strong working relationship, or have had success together in the past. Identifying these pairs can give us a better understanding of patterns and trends in the film industry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Approaches: For each movie, create pairs of the director and each actor. This could involve splitting the ‘Stars’ field if it contains multiple actors, and pairing each actor with the director. Count the occurrence of each director-actor pair to see which pairs occur most frequently. Visualize the most frequent director-actor pairs using a bar plot. This can make it easier to see which pairs work together most often."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create director-actor pairs for each movie, excluding pairs where the director and actor are the same\n",
        "director_actor_pairs = df_stars.apply(lambda row: (row['Director'], row['Stars_Split']) if row['Director'] != row['Stars_Split'] else None, axis=1)\n",
        "\n",
        "# Remove None values\n",
        "director_actor_pairs = director_actor_pairs.dropna()\n",
        "\n",
        "# Count the occurrence of each director-actor pair\n",
        "pair_counts = director_actor_pairs.value_counts()\n",
        "\n",
        "# Visualizing\n",
        "import matplotlib.pyplot as plt\n",
        "pair_counts.head(10).plot(kind='barh')\n",
        "plt.xlabel('Director-Actor Pair')\n",
        "plt.ylabel('Number of Movies')\n",
        "plt.title('Most Frequent Director-Actor Pairs')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Final Conclusion:\n",
        "\n",
        "1. Joel Coen - Ethan Coen\n",
        "2. Woody Allen - Mia Farrow\n",
        "3. John Ford - Henry Fonda\n",
        "4. George B. Seitz - Mickey Rooney\n",
        "5. George B. Seitz - Cecilia Parker\n",
        "\n",
        "These pairs have worked together on numerous projects, suggesting a strong professional relationship and a shared creative vision. Their repeated collaborations could also indicate that these pairs have found a successful formula that resonates with audiences and critics alike."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9.6) Question 6: What are the related movies that people may have interest in?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Purpose:**\n",
        "\n",
        "  When users finish watching a movie in our application, we want to keep them engaged by recommending similar films that captivate their interest and entice them to continue using the app.\n",
        "- **Approaches:**\n",
        "  1. To solve this problem we will use `Description` feature\n",
        "  2. Compute Term Frequency-Inverse Document Frequency (TF-IDF) vectors for each description.\n",
        "  3. Compute a similarity score\n",
        "  4. Return a list of top 10 most similar movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Some descriptions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_film['Description'].head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- TF-IDF matrix: Column represents a word in description. Row represents a film\n",
        "\n",
        "There are **6764 words** in total used in description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TF_IDF = TfidfVectorizer(stop_words='english') # remove 'the', 'a',...\n",
        "\n",
        "TF_IDF_matrix = TF_IDF.fit_transform(data_film['Description'])\n",
        "\n",
        "TF_IDF_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Compute **consine similarity score** by calculating dot product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "similarities = linear_kernel(TF_IDF_matrix, TF_IDF_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Function used to return related movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get index for each movie\n",
        "indexes = pd.Series(data_film.index, index=data_film['Name']).drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "indexes.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_related_movie(name, similarities=similarities):\n",
        "    # get index of 'name' film\n",
        "    idx = indexes[name]\n",
        "\n",
        "    # get the similarites of all the films with `name` film\n",
        "    similarity_scores = list(enumerate(similarities[idx]))\n",
        "\n",
        "    # sort similarity score and get top 10 films with highest similarity score with `name` film\n",
        "    similarity_scores = sorted(similarity_scores, key= lambda x: x[1], reverse=True)[1:11]\n",
        "\n",
        "    # get the index of top 10 films\n",
        "    movie_indexes = [score[0] for score in similarity_scores]\n",
        "\n",
        "    # get the name of top 10 films\n",
        "    return data_film['Name'].iloc[movie_indexes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Suggest related movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_related_movie('12 Người Đàn Ông Giận Dữ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_related_movie('Phù Thủy Xứ Oz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Conclusion**: based the importance of words in **description**, we can suggest some related movies to capture users attention and earn some benefits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem Statement 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **The question that our team want to give an answer to is:**  How much grosses can this new film can possibly get?\n",
        "- **Purpose:**\n",
        "  When we want to make a film, we sure want to know how much money the film could make for us. The success or failure of a movie depends on many factors: the release date, budget, star-power, marketing,...  But with the data that our team has collected, we will answer the question above by predicting the gross with values of: Ratings. \n",
        "  By predicting the gross, the film maker can know wheter it is possible to make the film and the prediction will help them to have a clearer vision on the production plan and distribution stage.\n",
        "- **How:** To solve this problem we will use Regression model to predict the Gross of the new movie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.hist(new_data_film['Gross(M$)']);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.heatmap(new_data_film.corr())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We will get the data from `data_film` that has the preprocessed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filmdata_df = data_film.copy()\n",
        "filmdata_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We will remove all the row in the DataFrame that has Gross equal to 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_cols = ['Rating', 'Gross(M$)']\n",
        "\n",
        "modeling_data = filmdata_df[feature_cols].copy()\n",
        "modeling_data['Gross(M$)'] = modeling_data['Gross(M$)'].fillna(0)\n",
        "modeling_data.Rating = modeling_data.Rating.fillna(0)\n",
        "modeling_data = modeling_data[~(modeling_data['Gross(M$)'] == 0)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Split the dataset into X_train, y_train, X_test, y_test and create Train dataset and Test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = modeling_data.drop(['Gross(M$)'], axis= 1), modeling_data['Gross(M$)']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = X_train.join(y_train)\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = X_test.join(y_test)\n",
        "test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- For the Regression model, our team choose Linear Regression and Ridge Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LinearRegression:\n",
        "    '''\n",
        "    lr: the learning rate\n",
        "    n_iters: the max iterations for the fit function to run\n",
        "    '''\n",
        "    def __init__(self, lr, n_iters):\n",
        "        self.lr = lr\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            y_pred = self.predict(X)\n",
        "\n",
        "            # Update the Weights and Bias\n",
        "            dW = - ( 2 * X.T.dot( y - y_pred ) ) / n_samples\n",
        "            db = - 2 * np.sum( y - y_pred ) / n_samples\n",
        "            self.weights = self.weights - self.lr *dW\n",
        "            self.bias = self.bias - self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = np.dot(X, self.weights) + self.bias\n",
        "        return y_pred\n",
        "    \n",
        "class RidgeRegression:\n",
        "    '''\n",
        "    lr: the learning rate\n",
        "    n_iters: the max iterations for the fit function to run\n",
        "    lamda: the values used to update the weights \n",
        "    '''\n",
        "    def __init__(self, lr, n_iters, lamda):\n",
        "        self.lr = lr\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.lamda = lamda \n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            y_pred = self.predict(X)\n",
        "            \n",
        "            # Update the Weights and Bias\n",
        "            dW = ( - ( 2 * ( X.T ).dot( y - y_pred ) ) +  ( 2 * self.lamda * self.weights ) ) / n_samples   \n",
        "            db = - 2 * np.sum( y - y_pred ) / n_samples\n",
        "            self.weights = self.weights - self.lr *dW\n",
        "            self.bias = self.bias - self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = np.dot(X, self.weights) + self.bias\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chosing Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- As for the Metrics, we will use the Mean Absolute Error and mse to have more insight of the error of each model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mae(y_test, predictions):\n",
        "    return np.mean(abs(y_test-predictions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Trainning and Validating Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- For the training and validating model, we will use K-Fold cross validation with 10 folds to train and validate the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initilizing Variables\n",
        "X_train, y_train = train_data.drop(['Gross(M$)'], axis= 1), train_data['Gross(M$)']\n",
        "X_test, y_test = test_data.drop(['Gross(M$)'], axis= 1), test_data['Gross(M$)']\n",
        "\n",
        "learning_rate = 0.0001\n",
        "n_iters = 1000\n",
        "lamda = 1000\n",
        "\n",
        "model_1 = LinearRegression(lr= learning_rate, n_iters =n_iters)\n",
        "model_2 = RidgeRegression(lr= learning_rate, n_iters =n_iters, lamda = lamda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def k_fold_cross_validation(n_folds, X, y, model):\n",
        "    kf = KFold(n_splits= n_folds, shuffle= True)\n",
        "    fold = kf.split(X, y)\n",
        "    mae_score = []\n",
        "    history = {}\n",
        "    count = 0\n",
        "    \n",
        "    for train_idx, val_idx in fold:\n",
        "        X_tr = X.iloc[train_idx]\n",
        "        y_tr = y.iloc[train_idx]\n",
        "        \n",
        "        X_val = X.iloc[val_idx]\n",
        "        y_val = y.iloc[val_idx]\n",
        "        \n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_val)\n",
        "        \n",
        "        new_mae = mae(y_val, y_pred)\n",
        "        mae_score.append(new_mae)\n",
        "        print(\"===== Fold\",count,\"=====\")\n",
        "        print(\"MSE=\", new_mae)\n",
        "        history[count] = new_mae\n",
        "        count+= 1\n",
        "        \n",
        "\n",
        "    avg_mse = np.mean(mae_score)\n",
        "    return avg_mse, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_fold = 10\n",
        "print(\"======= Linear Regression =======\")\n",
        "k_fold_linear, linear_history = k_fold_cross_validation(number_of_fold, X_train, y_train, model_1)\n",
        "print(\"===========================\")\n",
        "print(\"Avg. MAE= \", k_fold_linear)\n",
        "print()\n",
        "\n",
        "print(\"======= Ridge Regression =======\")\n",
        "k_fold_ridge, ridge_history= k_fold_cross_validation(number_of_fold, X_train, y_train, model_2)\n",
        "print(\"===========================\")\n",
        "print(\"Avg. MAE= \", k_fold_ridge)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Re-Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Re-train the model on the whole Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_1.fit(X_train, y_train)\n",
        "model_2.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Use the model to predict the Test dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model_1.predict(X_test)\n",
        "test_mae = mae(y_test, y_pred)\n",
        "print(\"Linear Regression Testing MAE= \", test_mae)\n",
        "\n",
        "y_pred = model_2.predict(X_test)\n",
        "test_mae = mae(y_test, y_pred)\n",
        "print(\"Ridge Regression Testing MAE= \", test_mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Both Linear Regression model and Ridge Regression model have nearly the same error. \n",
        "- The Mean Absolute Error of both models are quite high, about 54. But since we are working on the number million, 54 million is a acceptable value.\n",
        "- Clearly both of these models are not the most suitable model to predict the gross. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-  Running Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "history = []\n",
        "for i in range(len(linear_history)):\n",
        "  history.append(linear_history[i])\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history, label=[\"K-Fold Validation MAE\"])\n",
        "plt.title(\"linear model\")\n",
        "plt.xlabel(\"Fold\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.grid()\n",
        "plt.xticks(np.arange(0, 10, step=1))\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "history = []\n",
        "for i in range(len(ridge_history)):\n",
        "  history.append(ridge_history[i])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history, label=[\"K-Fold Validation MAE\"])\n",
        "plt.title(\"ridge model\")\n",
        "plt.xlabel(\"Fold\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.grid()\n",
        "plt.xticks(np.arange(0, 10, step=1))\n",
        "plt.legend(loc=\"lower right\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "y_pred_line_1 = model_1.predict(X)\n",
        "y_pred_line_2 = model_2.predict(X)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X, y, s=10)\n",
        "plt.plot(X, y_pred_line_1, color='red', linewidth=2)\n",
        "plt.title('Linear Regression')\n",
        "plt.xticks(np.arange(5, 10, 0.5))\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X, y, s=10)\n",
        "plt.plot(X, y_pred_line_2, color='red', linewidth=2)\n",
        "plt.title('Ridge Regression')\n",
        "plt.xticks(np.arange(5, 10, 0.5))\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> After fitting with 1 `Rating` feature, we found that the result is good. However, Our team want to improve the result more. Therefore we will choose a model to tuning its hyperparameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Best model for tuning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " - First, we will remove `Description` and `Name` feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_data_film = new_data_film.drop(columns=['Description', 'Name'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = new_data_film.drop('Gross(M$)', axis=1)\n",
        "y = new_data_film['Gross(M$)']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    'SVR':SVR(),\n",
        "    'XGBRegressor': XGBRegressor(),\n",
        "    'Ridge': linear_model.Ridge(),\n",
        "    'ElasticNet': ElasticNet(),\n",
        "    'SGDRegressor': SGDRegressor(),\n",
        "    'BayesianRidge': BayesianRidge(),\n",
        "    'LinearRegression': linear_model.LinearRegression(),\n",
        "    'RandomForestRegressor': RandomForestRegressor()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_results = []\n",
        "model_names = []\n",
        "\n",
        "for name,model in models.items():\n",
        "    a = model.fit(X_train,y_train)\n",
        "    predicted = a.predict(X_test)\n",
        "    score = mean_absolute_error(y_test, predicted)\n",
        "    model_results.append(score)\n",
        "    model_names.append(name)\n",
        "    \n",
        "    #creating dataframe\n",
        "    df_results = pd.DataFrame([model_names,model_results])\n",
        "    df_results = df_results.transpose()\n",
        "    df_results = df_results.rename(columns={0:'Model',1:'MAE'}).sort_values(by='MAE',ascending=False)\n",
        "    \n",
        "print(df_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> By far, `RandomForestRegressor` give us the best result so we will use this model for tuning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%time\n",
        "\n",
        "# import optuna\n",
        "\n",
        "# def objective(trial):\n",
        " \n",
        "#     param = {\n",
        "#         'n_estimators': trial.suggest_categorical('n_estimators', [100, 500, 1000, 1250, 1500, 2000]),\n",
        "#         'max_depth': trial.suggest_categorical('max_depth', [10, 25, 50, 100, 200]),\n",
        "#         'min_samples_split': trial.suggest_categorical('min_samples_split', [10, 25, 50, 100, 200]),\n",
        "#         'min_samples_leaf': trial.suggest_categorical('min_samples_leaf', [10, 25, 50, 100, 200]),\n",
        "#         'max_features': trial.suggest_categorical('max_features', [0.5, 1, 'sqrt'])\n",
        "#     }\n",
        "    \n",
        "#     model = RandomForestRegressor(**param)  \n",
        "    \n",
        "#     model.fit(X_train, y_train)\n",
        "#     preds_valid = model.predict(X_test)\n",
        "#     rmse = mean_squared_error(y_test, preds_valid, squared=False)\n",
        "#     return rmse\n",
        "\n",
        "    \n",
        "# study = optuna.create_study(direction=\"minimize\")\n",
        "# study.optimize(objective, n_trials=5000)\n",
        "\n",
        "# study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Best parameters for `RandomForestRegressor`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_params = {'n_estimators': 100,\n",
        " 'max_depth': 100,\n",
        " 'min_samples_split': 10,\n",
        " 'min_samples_leaf': 10,\n",
        " 'max_features': 0.5}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = RandomForestRegressor(**best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train)\n",
        "predicted = model.predict(X_test)\n",
        "print(f'Root Mean Square Error test = {mean_squared_error(y_test, predicted,squared=False)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_preds = model.predict(X_test)\n",
        "print(\"After Tuning, the MAE is\", mean_absolute_error(y_test, y_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(y_preds, y_test)\n",
        "plt.xlabel('True Values', fontsize=15)\n",
        "plt.ylabel('Predictions', fontsize=15)\n",
        "plt.title('The correctness of model prediction')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Conclusion**: With training on multiple models and hyperparameter tuning, the model does not improve. Therefore, the default parameters by far give us the best result. Our groups think that due to lacking observations, the model does not have enough data to learn. The tuning process takes place around 30 minutes to find the best combination of hyperparameter for RandomForestRegressor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Save predictions and true values to .csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = {\n",
        "    'predict_value': y_preds,\n",
        "    'true_value': y_test,\n",
        "}\n",
        "\n",
        "\n",
        "pd.DataFrame(result).to_csv('result.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. https://www.kaggle.com/code/heyrobin/house-price-prediction-beginner-s-notebook/notebook\n",
        "2. https://www.kaggle.com/code/ibtesama/getting-started-with-a-movie-recommendation-system"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
